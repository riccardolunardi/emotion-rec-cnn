{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqWxVIxakBM7"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Il dataset, prima di tutto, va opportunamente elaborato per occuparsi di eventuali dati duplicati o mancanti. Inoltre dovremo separare i dati per ottenere un training e un test set.\n",
        "Gli step che seguiremo saranno i seguenti:\n",
        "1. Caricare i dati\n",
        "2. Gestire i dati mancanti\n",
        "3. Eliminare le features ridondanti\n",
        "4. Dividere il dataset in training e test set\n",
        "5. Normalizzare e standardizzare i dati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Eoqv9IokKVC"
      },
      "source": [
        "### Definizione variabili\n",
        "\n",
        "Per facilità d'utilizzo si esplicitano qui i `valori delle variabili` del modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lunghezza percentuale del dataset di allenamento, il test è definito di conseguenza\n",
        "len_percentage_training = 80 / 100\n",
        "\n",
        "numero_di_features = 2\n",
        "output_CNN_1 = 20\n",
        "kernel_size_1 = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Librerie\n",
        "\n",
        "Allo stesso modo si inseriscono qui tutte le `librerie usate` per il progetto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1bpGRBckN8e"
      },
      "source": [
        "### Caricamento dei dati\n",
        "\n",
        "Tramite `pandas` e il dataset fornito in .csv, carichiamo i dati all'interno di un dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35887 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels        Usage\n",
              "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
              "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
              "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
              "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
              "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
              "...        ...                                                ...          ...\n",
              "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
              "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
              "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
              "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
              "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
              "\n",
              "[35887 rows x 3 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# if True:\n",
        "#     import kaggle\n",
        "#     kaggle.api.authenticate()\n",
        "#     kaggle.api.dataset_download_files('facial-expression-recognitionferchallenge', path='fer2013/fer2013/fer2013.csv', unzip=True)\n",
        "\n",
        "# else:\n",
        "#     fer2013 = pd.read_csv('files/fer2013.csv')\n",
        "\n",
        "fer2013 = pd.read_csv('files/fer2013.csv')\n",
        "fer2013"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eliminazione della colonna \"Usage\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['emotion', 'pixels', 'Usage']\n",
            "['emotion', 'pixels']\n"
          ]
        }
      ],
      "source": [
        "print(list(fer2013.columns))\n",
        "fer2013 = fer2013.drop(['Usage'], axis=1)\n",
        "print(list(fer2013.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHRZEl-Bka1a"
      },
      "source": [
        "### Divisione del data set in training e test set\n",
        "\n",
        "Si vuole dividere il data set in 2 parti:\n",
        "1. Training set\n",
        "2. Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lunghezza percentuale di:\n",
            "training_set 80%\n",
            "test_set 20%\n"
          ]
        }
      ],
      "source": [
        "training_set, test_set = np.split(fer2013, [ int(len_percentage_training * len(fer2013)) ] )\n",
        "\n",
        "print(\"Lunghezza percentuale di:\")\n",
        "print(\"training_set {:.0%}\".format( len(training_set) / len(fer2013) ))\n",
        "print(\"test_set {:.0%}\".format( len(test_set) / len(fer2013) ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mostrare le immagini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAY1ElEQVR4nO2dya9VVfOGF/aKoMBFQJEmXEAxogZsE02MJmogYjPRRONf5NA/wLkxxpjowDggOjAoiqIICHKR/tKDffcbab711nPPqXs+5Kvwe5/Z2qfObtbelb3rXbVqzfjrr7+aMaYel/2vT8AYw9g5jSmKndOYotg5jSmKndOYolwx6Mfx8fEg5Z49e7ZrX3XVVeF/ixcv7trnzp0LNmfOnOnaf/zxR7B58MEHu/bLL78cbNavX9+1r7766mBz6tSprj1z5sxgc8MNN4Rtp0+f7to//PDD0P/pddH/zp8/H2xUNf/tt9+CzZ9//jn0fH7++eewTfv2p59+Gnp8Qs/pl19+GXqsQ4cOBZtvv/22a09MTASbEydOdO1ff/012NA2ZcaMGWHbZZf17yR69vR/V1wRXUW30T3T/cydOzfY7N69O55k85vTmLLYOY0pip3TmKLYOY0pykBBiAJ+FVNIgFFRRAUZ2s9TTz0VbDZu3Ni177///mBz3XXXdW0SNq699tquTaIJiSvK77//HrapQKaiDf2P+lVtaD8KCRmXX3552KbCCYkbeny61iuvvHLoOamIRs/HkiVLhp6Pcvz48bAt00eZfdN16b7pudJtdD90Pyp0DcJvTmOKYuc0pih2TmOKMvCDnAZwMwPhGmPecccdwWbTpk1d+8knnww24+PjXVvjy9ZiTEED/BoHXXPNNcGGkik0Nr3++uuDjcaPFHfooDftR/9HiRt6LLoOihU16YBiboUG1GfNmtW1Kb7Vc6T7of0xe/bsYLNo0aKh+6E4UI9P/aH3etRkBu1XeoYysfxU+M1pTFHsnMYUxc5pTFHsnMYUZaAg9OOPP4ZtGnCTuKHJA88++2ywueuuu7r2nDlzgo2KTzTjQ4WLzMwAErHof5q8QMKBigKZJAgSUrSv6Xz0WLrf1li4UGhgXv9H4psmFNCAutrQAL9uo0QFPT6dD82u0WeGBDoV0ugZ1vtBYo9uI39R8SuTOPHPf9OWxpiLip3TmKLYOY0pysCYk76PNWn50UcfDTZPP/1019bKCK3F7346liaV0wCuDoyTTSb5WWOD1nKD1ZrAT0ntCsWFmhig195ajJ8yiejZc9Lrp3hOEwEoUUJjbup7jTHp/LSP6P5kqhPQc6XbSAPQvqW+1liVYk7dNx1rKvzmNKYodk5jimLnNKYodk5jijJQKVm1alXY9tJLL3Xtu+++O9iMjY11bSpFqdto8F7FHRospm2KihtZIUVFKwr4dcYLCTkqblDygJbY1P22FpMnSFzIJFjQ/9SGjp8Z4M+g95VmyWif0QwcEtb0OaJ7rQIUCX0qLFG/6n7ovk5nForiN6cxRbFzGlMUO6cxRRkYcz733HNhm8aYN954Y7DR+ICSlvV7neIH/V6nQefvv/++ax87dizYaPxEA+w0EK7nfdNNNwUbHRzXeLu11iYnJ7v24cOHg82CBQu69urVq4PNvn37ujbF2xS/aTxJA/oah1Kspvum+6rHojhdt1HMpzaZZSZai88RJSHotWWWbKA4PZPMMJ1E93AOI//TGPOvYuc0pih2TmOKYuc0pigDBaE1a9aEbSpCkLigsw4yAgQJMps3b+7aKv60Fsv0Hzx4MNgcOXKka5MAQTPd9RyXL18ebDRRQ4Wd1lqbN29e16aZ/yqsZWbgkABx8uTJsE1FCRosV3GFzlEhgUwH62kZBRXkSDTRGTBUGpP6SPdFNioAZdYmpb7WZ+ZCLQ/xN35zGlMUO6cxRbFzGlOUgR/AFHdo/JipAEdLAO7atatrf/XVV8FGY0NKKlebpUuXBptbbrmla+/ZsyfYHDp0KGzT+Gnnzp3B5q233uraGl+21tratWu79sMPPxxsNKbR5Qhai3E59QdV7dN9U/KC3kdKfFcoGfybb77p2po40VpMAqBz1mcmk3jeWozpSO8YBYpL9dkjm0zCw1T4zWlMUeycxhTFzmlMUeycxhRloCBEM0504JVmqOsg8/79+4ONDk6TsHTzzTd37RUrVgQbXRJAKwq0FmeKfPLJJ8Fm+/btYdvExETXzggQlOCgYhcJS3feeWfXfuihh4KNihvZJQrUjtbDHHas1mKiwo4dO4LNtm3bujbdV4WW2dBZKJllFVqLAgztWwUyEmn0eHT8TEKB/i+T8PA3fnMaUxQ7pzFFsXMaU5SBH80UL8ydO7drU7KvfufTgLZ+92uiQGsx0Zu++zXGohnzWh2BkpgpYV3jLoondd9ko/1IcZAm+VNSxsqVK7u2xqmtxST/1lpbt25d16Y+0v/RPdP/ffrpp8FGE+91+Y7WcgniGt9nBvgJip0zie+jLN2XSVTIVn5szW9OY8pi5zSmKHZOY4pi5zSmKAMFIZotoEIBBcE6o4CCaR3AJZFGkxdoNrzOAqEkhExpfUpM0BKWdB0q9tDAdEYU0FKQlLih1//ll18GmxdeeCFs0yQMqhbx/vvvd22qqKAJHzTbSMUWSu5QKJkikyiQWeogI8BkZorQ86nPPiVF6DlOZ3kGvzmNKYqd05ii2DmNKcrAmJPiSY27qNy+xkaUMK4D2kePHg02+n2eSaKm/WjsTAP1VB1A/0eV5BTqM41XaGBcEy4ysdL4+HjYRlUWtOrEBx98EGy2bNnStSm+1yQQihX1+aB7r31ESRmanJ9Z+oH2Tfcjk4SgNplkBkpAUaazbKLfnMYUxc5pTFHsnMYUxc5pTFEGCkK0RIEG5jTzPjOLXAf4aXBWhZutW7cGG11D9Isvvgg2mjhBa2jqDH6CKkNoQgNdq4oiNKCts32oxOb8+fO79j333BNsNJmgtZhgoeUrW4v3MbM8RWamBglbdP3DzocEISrdqiIRiTR63qNUNGgtPrMkLOl5uxKCMZcAdk5jimLnNKYodk5jijIwEqZAWTOCKJNkzpw5XZtmiqgoQIKQZhFR1v+rr77atTNZI/fee2+wWbhwYdimgpTOymgtCh6ZGTi0rqWu8/nAAw8EG+1XmklD2T96jzLrpZIAksl00iwuuh/aR5od1VoUcs6dOxdsZs6cGbb9W2RmrpD4lRGNpsJvTmOKYuc0pih2TmOKMjDmzMRP2SUBFI3xaGbC4sWLuzYNuk9OTnZtigv1O/+7774LNrfeeuvQc6TqAHqtlDyg8eRjjz0WbFavXt21aX1OTXjQRI7WeNBddQJKAsisY6n7pkQFhXQC1RLoOdOED9I/Mgkwo17rsP0SdB2Zig5T4TenMUWxcxpTFDunMUWxcxpTlOHp+IIGvRTg6uAwlapQAYgSFXTgWWdltNbaK6+80rX37t0bbHQbCQkkHGgSAq0xorNJXnzxxWCzYcOGrk3CgZZJIaEtsy4LJXOoHYk0Cs340DVXaJ1PPf6ePXuCTaZfVWyiGUGUAKOQkKPXRvcj85wrZKPik8uUGHMJYOc0pih2TmOKMjDmpHKR+g1NA9E66E1xkMZU9L2uSQg0EK1VDpYvXx5s9JwPHToUbDSZobUYB1MSxBNPPNG1qVyl7odirEy5Ro0dM+Uas2jSwzPPPBNstI9oDU8tH0rJ6Zr4T+VMtY/oukgn0FgxU3VhVLT/M6Vkp3M+fnMaUxQ7pzFFsXMaUxQ7pzFFmfasFB3ApcFqFXsyMyVo/RIVAbQSQGtxQJ3WU9EkCBJkqBLCxo0bu/b69euDjV4biSQqiFGCgZ53puwkiSQ0WK9CDq1PqmusLF26NNi8/fbbXZuEPp2Vs2PHjmCTEQN13zR4T5UH9N6SSKPPHgmNo8xcycxKmc5+/eY0pih2TmOKYuc0pigDY85Mki4lKmTWvdfvc6pIp/uhtUAVqqig8dMjjzwy1Ka1GL8dPHgw2Gg8SzG4JmhTzKlxD1WtyyRRU/yk8TT19UcffdS1X3vttWCjie6ZmI9iLI15KRFfY3DaDyXA6HNF/aj/yyQPZKBz1H3TJJAp9zftMzDGXBTsnMYUxc5pTFHsnMYUZdqzUjLChW7LlO3PBOWZWRg0O1+PRRUVMjNeSOzRc6TZ+XretB8l0x8kWtCAvgpQK1asCDb79+/v2lSaUytI0Dlq+VCahaHnSIkbum9KrsgIa9TXGRFPn+GMOEp9r6IZ+ctU+M1pTFHsnMYUxc5pTFEGxpyUsK7f65Ronlm6T/dN3+KZZQJ1QJkGxjV+oWPR4LDGGXT8TDypsRolM2i1BEry1/7IJHW3Fu/R2bNng40mYdA9m5iYGHosvVaKi3XfdCzdRppABkry133Rvde+zVQwcCUEY/6fYOc0pih2TmOKYuc0pigDo2waVNWAn9asHBsb69oUcOtgPYktGkxTwK3iDgkHGoTT+ZCQlJmNrwPo1GcqkGWErVmzZg09RxIX6Bz1eHp/Wov3g0QaTQQgsSfTZ3qPKHFEoQQUEqT0+HQ/9DnKLMdwoUpsTme2i9+cxhTFzmlMUeycxhRlYMxJ8ZvGPZl4gWIsjRcontR4hZIiqJKeooPwFD/QsoB6jqdOnQo22h+6JGBruQoGmQR6hRJAaPkD1QUoCUMnOdB+tP8p5tNrpXuv28hGn71M7DiV3TAyFQwoVlSbzLHpnKc8r7SlMeaiYuc0pih2TmOKYuc0pigDBaHMOpIkrmjQS/tRMSEzQ5wCbp0FQuLCuXPnujYNsJNIs2fPnq5NgtSyZcsGHqu12Ed0HSoAUZ/pNp3J0lprCxYsCNt0PVKaqaGJCdSPWlKTxEC9fuoPLV9KYosKUvR80Dnqs0diT6bCRmYGUCZRIbPu6lT4zWlMUeycxhTFzmlMUeycxhRloCBEGSgnTpzo2pkZHlT6UEWJzOwFKo+oATaJNhqo6zXQ+bQWs4aopKRm1pDYo9dG16piC4kkBw4c6NqZTJ/WomhGIo0KQpmsmcyamSQa6f8o00j7kZ5FOn6mhOWwYxEZIYdsVLSyIGTMJYCd05ii2DmNKcrAmHNycnLoDiju0UFm+qbX2JDW1dRlEyju0OPT7BKNiynG2bdvX9i2ZMmSrk1lLzWmIBtNeqDqEbqfTDlRiq/pfmg8TdeqfU3H136k+6o6AcVYtIyCkqk8kKmeQTOrMhU2/ptlFP6T/6aCgt+cxhTFzmlMUeycxhTFzmlMUQYKQpQ8oCUcM+IGoWITleXQgXkaPFdRJBOA01ohVJZD1w/Ztm1bsNGZItQf2o+UTDFv3ryuTSLF0aNHu/bu3buDza5du8K2zDojWoKFSnNm0PPOlBIhoU+hZ2qUkiStxWcks+4rlU5V8TFTzpR8air85jSmKHZOY4pi5zSmKAODERrQ129mSiLPrIepSQc0MK2xUqY8IdloPEU2t99+e9imMQSVvXz99de79tatW4ON9tFtt90WbO67776urdULWmvtyJEjQ20o5ladgOI3jfkpxtL7QdUatDrDKInorcU4kO4ZPVd6PIq3M/2ROW/to4ULFwYb8o8sfnMaUxQ7pzFFsXMaUxQ7pzFFGSgI6aB3a3HQn4JpHeSnYF6DchIyVHAgAUKFJKpooEG5lrNsrbVFixaFbToQvXbt2mDz/PPPd22qRPD11193bRqI/uyzz7o2JRMoNMA/Z86csE3PiQbd9b7SOepMlczgPc1u0fuYWR+TKm7QtkzChe47s6apPq+txcQV2o8+j5kEnb/xm9OYotg5jSmKndOYokw75tTYkGbj6zaKTXTmvbZbi9/5FHNqMjwNTGt1AlrGgGIBHWSmeObxxx/v2qtWrQo2uqzDm2++GWw+/PDDgcduLcZKlPhN1e40LqfEf9039aNeP/WH7pvuvd5XijkzSe10/MzyBxqrUl/rM5OJr6kKhv6PbKbCb05jimLnNKYodk5jimLnNKYoAwWhTDBNZSYzQbAOTlNQroO6NBCsg7wkGumalXQsEiB0Gwkp2h8kUuj1b9q0KdhoosDmzZuDjQonNJOHkhBU3NGqC63FfiOBLDOArjOZKClD90OD9yo8kkBFIo1eB91X+p+i95WqHGg/khinz1rm2P/Ypi2NMRcVO6cxRbFzGlOUgTEnVbvLJA1nloHTb/jMoDeh8QsNaGcGfjPJFJkEfopn9+/f37U1Bm6ttQ0bNnRtqnKg26h/KBk8M6CfqVqo/UjHUui+Zp4hjR0pEZ80AL0Ouna6j8P2QxMqNJmFbPQZmk7FQL85jSmKndOYotg5jSmKndOYogxUXCh4zaxpr8IBLXWgQgEtUaBiT2YdRTpWRhAikUAHjEnYUuGCRDS9trGxsWCTWaJAB/QpKYCSQjThgwSYzIyTjACUETz0vEk00m2UXELim96zTIIDofuh4x87dqxrZ2YE0Tq0U55D2tIYc1GxcxpTFDunMUUZGHNmvtcpNtFYgL7xNQ4ctfz/sGO3FuMXOh+K8TTG2rJlS7DRJRIoQXrx4sUD99taazt37uzalNSusSMtm0jV7rQfKcZTKHbM9KNCyR2Z5Tp0CQ0a4CdUOyCdQuNJstFnjZ4rtaF4X33ISQjGXALYOY0pip3TmKLYOY0pyrQFIQ3wM0IOJQHobA4SBXRWPa11qMciIUUHvemc9+3bF7a99957XZtmiqgAkSnbPzExEWx05srKlSuDje47M2uHoOtXUYTWZlWxi5IgMoKM3mu69ySuKJmqAtRHerxREifo+JOTk8FGK1NkxLh/9p+2NMZcVOycxhTFzmlMUQYGLZQMrgPPNOitMSbFrrotU4mAEgX0fCjm03Pcu3dvsHnjjTfCtt27d3dtisN0cJzia43xKHlAYxE6x+XLl3dtiqcoUUNjo0ySPyUY6DbqDz0nijn1f9QfajNqAjvF1xo/UuyqfUTH0nOi/tDnYTo6gd+cxhTFzmlMUeycxhTFzmlMUaa9HEOGzFqPWjGAgvLMILOKRDSgrIH6O++8E2x0fczWorhCQooen641s7RAZpaO9lkm4YL2Rf2aSQzIlCHVag1UGUKFPhKx9NnLCDsEzQDKVIbQa8s8i3Q+eo+ys2ta85vTmLLYOY0pip3TmKLYOY0pykBBiEQBDZ5HDdQzaDZFZs1IEhe2b9/etancCGWp6L4zpTtIONA+IgFCj0WZThmBijJQMmKGilaUETPKGp6UNZMRhPT4o2YIESo2ZbJ/qK/1eSABlWZSZfGb05ii2DmNKYqd05iiDIw5acaJfp9TPKPf3hRT6Pe6Dl63xvHKMBv6z8cff9y1Dxw4EGwuVExDsYkOhGfW+SQbjdWyMxz0ftD/dLCc+oNm+iuadEAVDfQeXajEidbic0XXoTaZSgijVl3Qe+9ZKcZcAtg5jSmKndOYotg5jSnKwOiUBJFMOQu1oQF1DfhJAMmcjwoOVN5j27ZtXTszc4TIlPcgMn2m/ZEpO5nps9ZypTK0H0lYU4GQZnycPn26a589ezbY6MwM6g+9NhJtMkJOJsEg+79hkICqYqhLYxpzCWDnNKYodk5jijLt5Rj0m5kS3zUWyMz+ziQzEBorHTt2bKgNxSqZ2JHIxH2ZWfXarxSnaxxK5UQp7lE7uq8aP1LiiMauFJdqzJlZVoHuR2bSwahkSoUqmSSVjP6SiXf/+W/a0hhzUbFzGlMUO6cxRbFzGlOUgYIQCQ5KRjigNU404KfBah0sp/NRwYHKRaq4kq3UMMoaIxlhKSNA0LVm1oWh/9E9UkYpM3nmzJlgo+IfXSuJiMqFFICUbPLGMPR+UFKGMp3r8pvTmKLYOY0pip3TmKJMOwkhM2Nfkwcy3+KUjK1xEA3yajy7bNmyYLN+/fqu/e677wYbSkjWAf3MIDOh+84kVVMCRiZpOjPITfvRWJHiQo1dKQkhE4PrtVEclrG5mFByhz7XtDar/i8T//+N35zGFMXOaUxR7JzGFMXOaUxRpl0JQYWCjHBANrpvEkBUTKCAW4UCGphfs2ZN1/7888+Djc6moP8dP3482Ki4QgPzowhiGUEoO5iu+6KEA7WhZIaTJ092bRJ7Mvf1YkLHz4hLGVFTr5/6bDqlMMP+R/6nMeZfxc5pTFHsnMYUZeAHMcUUGudQPKmxWWZZPIoNMonvmcp28+bN69rr1q0LNhSHjY2NdW1Kztdrpbj0yJEjXZsqQ2SS2hWyyVSvoOoE+r8LHT/9J6odzJw5M9hofDsq9FxlEu8zOoH2GcWy2o+uvmfMJYCd05ii2DmNKYqd05iiTDvCz1QHmD9/fn+QhJCQKY+YmeFAAbdWR1i5cmXq+Fpmk0QCvX6q+qD9QTYqCJFoQ0kYCl1/RoQ4f/581yZhSY+fSYIgQUa36bEJEvronum10vEzz9UoiQrZChtZ/OY0pih2TmOKYuc0pigDg0H67tYB3ExlvcygL8U4mXhOk+wpftBts2fPHmrTWmvj4+Nde/v27cHm1KlTA9uttXb48OGwbdjxM4kKFOPQTHvtW4pBM1UnMlUW9JmhZ0j3Q/tVnYLuD2kZOuifSc6nftR9Z+LJUZd2nAq/OY0pip3TmKLYOY0pip3TmKLM+F/PVDfGMH5zGlMUO6cxRbFzGlMUO6cxRbFzGlMUO6cxRfk/xT36vANHLksAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def show(img):\n",
        "\n",
        "    img = img.split(\" \")\n",
        "    img = np.array([float(item) for item in img])\n",
        "    showImg = img.reshape(48,48)\n",
        "    \n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(showImg, cmap = 'gray')\n",
        "\n",
        "# show(test_set.pixels.values[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZBBY8Yvkfwl"
      },
      "source": [
        "### Normalizzazione dei dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modello con CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VGG16 Schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200219152327/conv-layers-vgg16.jpg\" alt=\"drawing\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definizione del modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Emotion_CNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Emotion_CNN, self).__init__()\n",
        "    \n",
        "        self.l_cnn_1 = torch.nn.Conv2d()\n",
        "        self.l_norm_1 = torch.nn.BatchNorm2d()\n",
        "        self.l_relu_1 = torch.nn.ReLU()\n",
        "        self.l_pool_1 = torch.nn.MaxPool2d()\n",
        "\n",
        "        self.l_cnn_2 = torch.nn.Conv2d()\n",
        "        self.l_norm_2 = torch.nn.BatchNorm2d()\n",
        "        self.l_relu_2 = torch.nn.ReLU()\n",
        "        self.l_pool_2 = torch.nn.MaxPool2d()\n",
        "\n",
        "        self.l_linear = torch.nn.Linear()\n",
        "\n",
        "    def forward(self, x):        \n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        lstm_out, self.hidden = self.l_lstm(x)\n",
        "        x = lstm_out.contiguous().view(batch_size,-1)\n",
        "        return self.l_linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Sito da cui ho preso il modello successivo](https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class Net(Module):   \n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#\n",
        "#         self.cnn_layers = Sequential(\n",
        "#             # Defining a 2D convolution layer\n",
        "#             Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
        "#             BatchNorm2d(4),\n",
        "#             ReLU(inplace=True),\n",
        "#             MaxPool2d(kernel_size=2, stride=2),\n",
        "#             # Defining another 2D convolution layer\n",
        "#             Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "#             BatchNorm2d(4),\n",
        "#             ReLU(inplace=True),\n",
        "#             MaxPool2d(kernel_size=2, stride=2),\n",
        "#         )\n",
        "# \n",
        "#         self.linear_layers = Sequential(\n",
        "#             Linear(4 * 7 * 7, 10)\n",
        "#         )\n",
        "# \n",
        "#     # Defining the forward pass    \n",
        "#     def forward(self, x):\n",
        "#         x = self.cnn_layers(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.linear_layers(x)\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Istanza del modello\n",
        "\n",
        "Qua Lunni dobbiamo fare attenzione a `impostare il device in base all'ambiente` (Colab o locale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "model = Emotion_CNN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.MSELoss()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Divisione in Tensori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creazione dei DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definizione di Training e Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Allenamento e Validazione del modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizzazione grafico della loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Salva stato del modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carica stato del modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predizione e valutazione del modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classificazione di Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Valutazione del modello"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GqWxVIxakBM7"
      ],
      "name": "emotion-cnn-dabrosca-lunardi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
