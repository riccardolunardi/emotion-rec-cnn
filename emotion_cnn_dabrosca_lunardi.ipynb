{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqWxVIxakBM7"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Il dataset, prima di tutto, va opportunamente elaborato per occuparsi di eventuali dati duplicati o mancanti. Inoltre dovremo separare i dati per ottenere un training e un test set.\n",
        "Gli step che seguiremo saranno i seguenti:\n",
        "1. Caricare i dati\n",
        "2. Gestire i dati mancanti\n",
        "3. Eliminare le features ridondanti\n",
        "4. Dividere il dataset in training e test set\n",
        "5. Normalizzare e standardizzare i dati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Eoqv9IokKVC"
      },
      "source": [
        "### Definizione variabili\n",
        "\n",
        "Per facilità d'utilizzo si esplicitano qui i `valori delle variabili` del modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lunghezza percentuale del dataset di allenamento, il test è definito di conseguenza\n",
        "len_percentage_train = 80 / 100\n",
        "\n",
        "numero_di_features = 2\n",
        "output_CNN_1 = 20\n",
        "kernel_size_1 = 2\n",
        "\n",
        "lunni = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Librerie\n",
        "\n",
        "Allo stesso modo si inseriscono qui tutte le `librerie usate` per il progetto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1bpGRBckN8e"
      },
      "source": [
        "### Caricamento dei dati\n",
        "\n",
        "Tramite `pandas` e il dataset fornito in .csv, carichiamo i dati all'interno di un dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35887 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels        Usage\n",
              "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
              "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
              "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
              "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
              "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
              "...        ...                                                ...          ...\n",
              "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
              "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
              "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
              "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
              "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
              "\n",
              "[35887 rows x 3 columns]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    if lunni:\n",
        "        fer2013 = pd.read_csv('/content/drive/My Drive//Università//Deep Learning//emotion-cnn//files//fer2013.csv') # LUNNI\n",
        "    else:\n",
        "        fer2013 = pd.read_csv('/content/drive/My Drive//Università//Deep Learning//emotion-cnn//files//fer2013.csv') # GIAN\n",
        "else:\n",
        "    fer2013 = pd.read_csv('files/fer2013.csv')\n",
        "fer2013"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eliminazione della colonna \"Usage\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['emotion', 'pixels', 'Usage']\n",
            "['emotion', 'pixels']\n"
          ]
        }
      ],
      "source": [
        "print(list(fer2013.columns))\n",
        "fer2013 = fer2013.drop(['Usage'], axis=1)\n",
        "print(list(fer2013.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Da stringa di Pixels a List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "fer2013.pixels = fer2013.pixels.apply(lambda x: np.array(x.split(' ')).reshape(1, 48, 48).astype('float32') / 255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Salvo dataframe normalizzato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "fer2013.to_pickle(\"files/fer_norm.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carico dataframe normalizzato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[[[0.27450982, 0.3137255, 0.32156864, 0.282352...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[[[0.5921569, 0.5882353, 0.5764706, 0.60784316...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[[[0.90588236, 0.83137256, 0.6117647, 0.643137...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[[[0.09411765, 0.1254902, 0.14117648, 0.117647...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>[[[0.015686275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>[[[0.19607843, 0.14117648, 0.06666667, 0.08627...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>[[[0.69803923, 0.68235296, 0.6745098, 0.678431...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>[[[0.06666667, 0.06666667, 0.0627451, 0.090196...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>[[[0.11764706, 0.10980392, 0.10980392, 0.11372...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>[[[0.07450981, 0.050980393, 0.05490196, 0.0470...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35887 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels\n",
              "0            0  [[[0.27450982, 0.3137255, 0.32156864, 0.282352...\n",
              "1            0  [[[0.5921569, 0.5882353, 0.5764706, 0.60784316...\n",
              "2            2  [[[0.90588236, 0.83137256, 0.6117647, 0.643137...\n",
              "3            4  [[[0.09411765, 0.1254902, 0.14117648, 0.117647...\n",
              "4            6  [[[0.015686275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "...        ...                                                ...\n",
              "35882        6  [[[0.19607843, 0.14117648, 0.06666667, 0.08627...\n",
              "35883        3  [[[0.69803923, 0.68235296, 0.6745098, 0.678431...\n",
              "35884        0  [[[0.06666667, 0.06666667, 0.0627451, 0.090196...\n",
              "35885        3  [[[0.11764706, 0.10980392, 0.10980392, 0.11372...\n",
              "35886        2  [[[0.07450981, 0.050980393, 0.05490196, 0.0470...\n",
              "\n",
              "[35887 rows x 2 columns]"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fer2013 = pd.read_pickle(\"files/fer_norm.pkl\")\n",
        "fer2013"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHRZEl-Bka1a"
      },
      "source": [
        "### Divisione del data set in training e test set\n",
        "\n",
        "Si vuole dividere il data set in 2 parti:\n",
        "1. Train set\n",
        "2. Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lunghezza percentuale di:\n",
            "train_set 80%\n",
            "test_set 20%\n"
          ]
        }
      ],
      "source": [
        "train_set, test_set = np.split(fer2013, [ int(len_percentage_train * len(fer2013)) ] )\n",
        "test_set.reset_index(inplace=True, drop=True)\n",
        "\n",
        "print(\"Lunghezza percentuale di:\")\n",
        "print(\"train_set {:.0%}\".format( len(train_set) / len(fer2013) ))\n",
        "print(\"test_set {:.0%}\".format( len(test_set) / len(fer2013) ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creazione tensori e dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x, train_y = torch.tensor(train_set.pixels), torch.tensor(train_set.emotion)\n",
        "test_x, test_y = torch.tensor(test_set.pixels), torch.tensor(test_set.emotion)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_x, test_y)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=False, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, drop_last=True)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mostrare le immagini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def show(img):\n",
        "    img = img * 255\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img, cmap = 'gray')\n",
        "\n",
        "show(fer2013.pixels[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modello con CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VGG16 Schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200219152327/conv-layers-vgg16.jpg\" alt=\"drawing\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definizione del modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Emotion_CNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Emotion_CNN, self).__init__()\n",
        "    \n",
        "        self.cnn_layers = torch.nn.Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            torch.nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(4),\n",
        "            # Da guardare se inplace = True ha senso\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Defining another 2D convolution layer\n",
        "            torch.nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(4),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        " \n",
        "        self.linear_layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(4 * 12 * 12, 10)\n",
        "        )\n",
        " \n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Sito da cui ho preso il modello successivo](https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class Net(Module):   \n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#\n",
        "#         self.cnn_layers = Sequential(\n",
        "#             # Defining a 2D convolution layer\n",
        "#             Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
        "#             BatchNorm2d(4),\n",
        "#             ReLU(inplace=True),\n",
        "#             MaxPool2d(kernel_size=2, stride=2),\n",
        "#             # Defining another 2D convolution layer\n",
        "#             Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "#             BatchNorm2d(4),\n",
        "#             ReLU(inplace=True),\n",
        "#             MaxPool2d(kernel_size=2, stride=2),\n",
        "#         )\n",
        "# \n",
        "#         self.linear_layers = Sequential(\n",
        "#             Linear(4 * 7 * 7, 10)\n",
        "#         )\n",
        "# \n",
        "#     # Defining the forward pass    \n",
        "#     def forward(self, x):\n",
        "#         x = self.cnn_layers(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.linear_layers(x)\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Istanza del modello\n",
        "\n",
        "Qua Lunni dobbiamo fare attenzione a `impostare il device in base all'ambiente` (Colab o locale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "model = Emotion_CNN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definizione di Training e Validation\n",
        "\n",
        "After building your model, you need to select a loss function (e.g. `cross entropy`), and an optimization module, along with a learning rate. Train and test your CNN model using the usual pipeline we have seen during the practical lessons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "def Train(epoca):\n",
        "    running_loss = .0\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    # valori_previsti_lista = []\n",
        "    # valori_veri_lista = []\n",
        "\n",
        "    for idx, (inputs,labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        preds = model(inputs.float())\n",
        "        # preds = torch.squeeze(preds)\n",
        "        # labels = torch.squeeze(labels)\n",
        "\n",
        "        # valori_veri_lista.append((labels.detach().numpy() * standard_scaler.scale_[2]) + standard_scaler.mean_[2])\n",
        "        # valori_previsti_lista.append((preds.detach().numpy() * standard_scaler.scale_[2]) + standard_scaler.mean_[2])\n",
        "\n",
        "        loss = criterion(preds,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss\n",
        "\n",
        "    # confronto = pd.DataFrame(np.array([valori_veri_lista, valori_previsti_lista]).transpose(), index=list(range(len(valori_veri_lista))), columns=['veri', 'predetti'])\n",
        "    # confronto.to_csv(\"files/training_epoch_\" + str(epoca) + \".csv\")\n",
        "\n",
        "    train_loss = running_loss/len(train_loader)\n",
        "    train_losses.append(train_loss.detach().cpu().data.numpy())\n",
        "    \n",
        "    print(f'train_loss {train_loss}')\n",
        "    \n",
        "def Valid():\n",
        "    running_loss = .0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(inputs.float())\n",
        "            # preds = torch.squeeze(preds)\n",
        "            # labels = torch.squeeze(labels)\n",
        "            loss = criterion(preds,labels)\n",
        "            running_loss += loss\n",
        "            \n",
        "        valid_loss = running_loss/len(test_loader)\n",
        "        valid_losses.append(valid_loss.detach().cpu().data.numpy())\n",
        "        print(f'valid_loss {valid_loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Allenamento e Validazione del modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs 1/10\n",
            "train_loss 1.7124146223068237\n",
            "valid_loss 1.7435275316238403\n",
            "epochs 2/10\n",
            "train_loss 1.6667674779891968\n",
            "valid_loss 1.714720368385315\n",
            "epochs 3/10\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/sp/61g444z97mb91t3qgh0lttn40000gn/T/ipykernel_10051/602874184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs {}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mValid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/sp/61g444z97mb91t3qgh0lttn40000gn/T/ipykernel_10051/4036053510.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(epoca)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('epochs {}/{}'.format(epoch+1,epochs))\n",
        "    Train(epoch + 1)\n",
        "    Valid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizzazione grafico della loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_df = pd.DataFrame( {'Train Losses':train_losses, 'Valid Losses':valid_losses }, index=list(range(len(train_losses))) )\n",
        "\n",
        "loss_df=loss_df.astype(float)\n",
        "\n",
        "xs = loss_df.plot()\n",
        "_ = xs.set_ylabel(\"loss\")\n",
        "_ = xs.set_xlabel(\"epoch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Salva stato del modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'files/saved_state_of_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carica stato del modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('files/saved_state_of_model.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predizione e valutazione del modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classificazione di Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Valutazione del modello"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GqWxVIxakBM7"
      ],
      "name": "emotion-cnn-dabrosca-lunardi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
